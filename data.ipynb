{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pip install jupyter-black"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datapreparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_REFERENCES = \"./data/raw/references.json\"\n",
    "PATH_TO_CROWD_DATA = \"./data/raw/anonymized_project.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load references\n",
    "references = pd.read_json(PATH_TO_REFERENCES, orient=\"index\")\n",
    "references = references.reset_index(names=\"img\")\n",
    "references.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_CROWD_DATA, \"r\") as f:\n",
    "    crowddata_json = json.load(f)\n",
    "crowddata = pd.DataFrame.from_dict(\n",
    "    crowddata_json[\"results\"][\"root_node\"][\"results\"],\n",
    "    orient=\"index\",\n",
    ")\n",
    "crowddata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowddata[\"gui_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowddataframe = pd.DataFrame()\n",
    "# loop over 'results'\n",
    "for key in crowddata_json[\"results\"][\"root_node\"][\"results\"].keys():\n",
    "    if crowddataframe is None:\n",
    "        crowddataframe = pd.json_normalize(\n",
    "            crowddata_json[\"results\"][\"root_node\"][\"results\"][key][\"results\"]\n",
    "        )\n",
    "    else:\n",
    "        normlist = pd.json_normalize(\n",
    "            crowddata_json[\"results\"][\"root_node\"][\"results\"][key][\"results\"]\n",
    "        )\n",
    "        crowddataframe = pd.concat([crowddataframe, normlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowddataframe.to_csv(\"./data/project.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowddataframe.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1 - Gather insights about the annotators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    crowddataframe[\"user.vendor_id\"].unique(),\n",
    "    len(crowddataframe[\"user.vendor_id\"].unique()),\n",
    ")\n",
    "print(\n",
    "    crowddataframe[\"user.vendor_user_id\"].unique(),\n",
    "    len(crowddataframe[\"user.vendor_user_id\"].unique()),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) 22 Annotator (1 Vendor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowddataframe[\"task_output.duration_ms\"].min(), crowddataframe[\n",
    "    \"task_output.duration_ms\"\n",
    "].max(), crowddataframe[\"task_output.duration_ms\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = crowddataframe[\"task_output.duration_ms\"] > 0\n",
    "len(crowddataframe), len(crowddataframe[m]), len(crowddataframe[~m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_crowddataframe = crowddataframe[m]\n",
    "valid_crowddataframe[\"task_output.duration_ms\"].min(), valid_crowddataframe[\n",
    "    \"task_output.duration_ms\"\n",
    "].max(), valid_crowddataframe[\"task_output.duration_ms\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "HIST_BINS = 1000\n",
    "_, _, bar_container = ax.hist(\n",
    "    valid_crowddataframe[\"task_output.duration_ms\"], HIST_BINS\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = valid_crowddataframe[\"task_output.duration_ms\"].quantile([0.05, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_crowddataframe[\"task_output.duration_ms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "HIST_BINS = 1000\n",
    "_, _, bar_container = ax.hist(\n",
    "    valid_crowddataframe[\"task_output.duration_ms\"], HIST_BINS\n",
    ")\n",
    "ax.set_xlim(xmax=quant[0.95])\n",
    "ax.set_xlim(xmin=quant[0.05])\n",
    "ax.set_xlabel(\"Sections (quantile 0.05 0.95)\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "# ax.set_title('Histogram')\n",
    "m = valid_crowddataframe[\"task_output.duration_ms\"].mean()\n",
    "plt.axvline(m, color=\"r\")  # vertical\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b) \n",
    "\n",
    "Alle Datenpunkte\n",
    "* Min 10\n",
    "* Max 42398\n",
    "* Mean 1289.9\n",
    "\n",
    "\n",
    "Negative Datenpunkte aussortiert (Anz:6)\n",
    "* Min -99999\n",
    "* Max 42398\n",
    "* Mean 1284.3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anz_annotation_by_user = crowddataframe.groupby(\"user.vendor_user_id\").agg(\n",
    "    {\"user.vendor_user_id\": \"count\"}\n",
    ")\n",
    "anz_annotation_by_user = anz_annotation_by_user.rename(\n",
    "    columns={\"user.vendor_user_id\": \"count\"}\n",
    ").sort_values(by=[\"count\"])\n",
    "print(anz_annotation_by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_nr = anz_annotation_by_user.reset_index()[\"user.vendor_user_id\"].apply(\n",
    "    lambda x: x[-2:]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(annotator_nr, anz_annotation_by_user[\"count\"])\n",
    "\n",
    "ax.set_xlabel(\"22 Annotators\")\n",
    "ax.set_ylabel(\"Annotation Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotationdata = crowddataframe[\n",
    "    [\n",
    "        \"root_input.image_url\",\n",
    "        \"user.vendor_user_id\",\n",
    "        \"task_output.corrupt_data\",\n",
    "        \"task_output.cant_solve\",\n",
    "        \"task_output.answer\",\n",
    "    ]\n",
    "].copy()  # settingwithcopywarning\n",
    "annotationdata[\"answer_y\"] = annotationdata[\"task_output.answer\"] == \"yes\"\n",
    "annotationdata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = 8\n",
    "lower_limit = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_by_image = (\n",
    "    annotationdata.groupby([\"root_input.image_url\"])[\"answer_y\"].sum().reset_index()\n",
    ")\n",
    "disagree_images = answers_by_image[\n",
    "    (answers_by_image[\"answer_y\"] < upper_limit)\n",
    "    & (lower_limit < answers_by_image[\"answer_y\"])\n",
    "][\"root_input.image_url\"].to_list()\n",
    "print(len(disagree_images))\n",
    "disagree_images[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotationdata = crowddataframe[\n",
    "    [\n",
    "        \"root_input.image_url\",\n",
    "        \"user.vendor_user_id\",\n",
    "        \"task_output.corrupt_data\",\n",
    "        \"task_output.cant_solve\",\n",
    "        \"task_output.answer\",\n",
    "        \"task_output.duration_ms\",\n",
    "    ]\n",
    "].copy()  # settingwithcopywarning\n",
    "annotationdata[\"answer_y\"] = annotationdata[\"task_output.answer\"] == \"yes\"\n",
    "annotationdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of 'corrupted', 'cant solve', 'both'\n",
    "len(annotationdata[annotationdata[\"task_output.corrupt_data\"]]), len(\n",
    "    annotationdata[annotationdata[\"task_output.cant_solve\"]]\n",
    "), len(\n",
    "    annotationdata[\n",
    "        annotationdata[\"task_output.corrupt_data\"]\n",
    "        & annotationdata[\"task_output.cant_solve\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -> 4, 17 ,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Really corrupted? (corrupt_data > 1)\n",
    "count_cant_solve = (\n",
    "    annotationdata[annotationdata[\"task_output.corrupt_data\"]]\n",
    "    .groupby(\"root_input.image_url\")[\"task_output.corrupt_data\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")\n",
    "len(count_cant_solve[count_cant_solve[\"task_output.corrupt_data\"] > 1])\n",
    "\n",
    "# -> 0 No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Really cant solve? (cant'solve > 1)\n",
    "count_cant_Solve = (\n",
    "    annotationdata[annotationdata[\"task_output.cant_solve\"]]\n",
    "    .groupby(\"root_input.image_url\")[\"task_output.cant_solve\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")\n",
    "len(count_cant_Solve[count_cant_Solve[\"task_output.cant_solve\"] > 1])\n",
    "# -> 0 No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check 'problems' with duration # mean duration: ~1300\n",
    "annotationdata[\n",
    "    annotationdata[\"task_output.corrupt_data\"]\n",
    "    | annotationdata[\"task_output.cant_solve\"]\n",
    "][\"task_output.duration_ms\"].hist()\n",
    "\n",
    "# -> faster then mean but not to fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems & disagree\n",
    "problem_annotations = annotationdata[\n",
    "    annotationdata[\"task_output.corrupt_data\"]\n",
    "    | annotationdata[\"task_output.cant_solve\"]\n",
    "]\n",
    "len(\n",
    "    problem_annotations[\n",
    "        problem_annotations[\"root_input.image_url\"].isin(disagree_images)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotators corrupted\n",
    "user_corrupt_data = (\n",
    "    annotationdata[annotationdata[\"task_output.corrupt_data\"]][\"user.vendor_user_id\"]\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "user_corrupt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotators can't solve\n",
    "user_cant_solve = (\n",
    "    annotationdata[annotationdata[\"task_output.cant_solve\"]][\"user.vendor_user_id\"]\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "user_cant_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotators both\n",
    "[i for i in user_cant_solve if i in user_corrupt_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_with_problems = user_cant_solve.copy()\n",
    "user_with_problems.extend(user_corrupt_data)\n",
    "user_with_problems = list(set(user_with_problems))\n",
    "user_with_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check % yes/no\n",
    "annotation_cup = (\n",
    "    annotationdata[annotationdata[\"user.vendor_user_id\"].isin(user_with_problems)]\n",
    "    .groupby(\"user.vendor_user_id\")[\"answer_y\"]\n",
    "    .agg([\"count\", \"sum\"])\n",
    "    .reset_index()\n",
    ")\n",
    "annotation_cup[\"%\"] = annotation_cup[\"sum\"] / annotation_cup[\"count\"]\n",
    "annotation_cup\n",
    "# -> ~50/50 expected -> ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature disagree\n",
    "crowddataframe[\"disagree\"] = crowddataframe[\"root_input.image_url\"].isin(\n",
    "    disagree_images\n",
    ")\n",
    "\n",
    "# create crowd dataset\n",
    "crowd_data_set = crowddataframe[\n",
    "    [\n",
    "        \"root_input.image_url\",\n",
    "        \"disagree\",\n",
    "    ]\n",
    "].copy()  # settingwithcopywarning\n",
    "\n",
    "crowd_data_set = crowd_data_set.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_y = answers_by_image.set_index(\"root_input.image_url\")\n",
    "\n",
    "\n",
    "# (> 5 / < 5 -> carefull:  i don't care about disagree images)\n",
    "def converter(img_name):\n",
    "    value = answer_y.loc[img_name, \"answer_y\"]\n",
    "    if value > 5:\n",
    "        return True\n",
    "    elif 5 > value:\n",
    "        return False\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowd_data_set[\"bicycle?\"] = crowd_data_set[\"root_input.image_url\"].apply(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_is_bicycle = len(crowd_data_set[crowd_data_set[\"bicycle?\"] == True])\n",
    "c_is_not_bycle = len(crowd_data_set[crowd_data_set[\"bicycle?\"] == False])\n",
    "c_unkown_bycle = len(crowd_data_set[crowd_data_set[\"bicycle?\"] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "c_is_bicycle = len(crowd_data_set[crowd_data_set[\"bicycle?\"] == True])\n",
    "c_is_not_bycle = len(crowd_data_set[crowd_data_set[\"bicycle?\"] == False])\n",
    "c_unkown_bycle = len(crowd_data_set[crowd_data_set[\"bicycle?\"] == -1])\n",
    "\n",
    "c_is_bicycle, c_is_not_bycle, c_unkown_bycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 2))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "# ax.bar(['Bicycle','No Bicycle'], [len(crowd_data_set[crowd_data_set['bicycle?']==True]),len(crowd_data_set[crowd_data_set['bicycle?']==False])])\n",
    "b1 = ax.bar([\"Bicycle\"], c_is_bicycle)\n",
    "b2 = ax.bar(\"No Bicycle\", c_is_not_bycle)\n",
    "ax.set_xlabel(\"Class label\")\n",
    "ax.set_ylabel(\"Number of samples\")\n",
    "ax.set_title(\"Class distribution in dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add image name\n",
    "crowddataframe[\"img\"] = crowddataframe[\"root_input.image_url\"].apply(\n",
    "    lambda s: s[-12:-4]\n",
    ")\n",
    "# add truth to dataset\n",
    "crowddata_truth = crowddataframe.merge(references, on=\"img\", how=\"left\")\n",
    "crowddata_truth.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowddata_truth[\"answer_bool\"] = crowddata_truth[\"task_output.answer\"] != \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong labeled\n",
    "\n",
    "crowddata_truth[\"correct_annotation\"] = (\n",
    "    crowddata_truth[\"answer_bool\"] == crowddata_truth[\"is_bicycle\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowddata_truth.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crowddata_truth.groupby(\"user.vendor_user_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "annotation_count = (\n",
    "    crowddata_truth.groupby(\"user.vendor_user_id\")[\"correct_annotation\"]\n",
    "    .agg([\"count\", \"sum\"])\n",
    "    .reset_index()\n",
    ")\n",
    "annotation_count[\"relativ\"] = annotation_count[\"sum\"] / annotation_count[\"count\"]\n",
    "annotation_count = annotation_count.sort_values(\"relativ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "annotator_nr = annotation_count[\"user.vendor_user_id\"].apply(lambda x: x[-2:])\n",
    "\n",
    "ax.scatter(annotator_nr, annotation_count[\"relativ\"])\n",
    "\n",
    "ax.set_xlabel(\"Annotator\")\n",
    "ax.set_ylabel(\"% correct\")\n",
    "ax.set_title(\"Annotation-Quality\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crowdeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
